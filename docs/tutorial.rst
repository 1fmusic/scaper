.. _tutorial:

Scaper tutorial
===============

Introduction
------------
Welcome to the scaper tutorial! In this tutorial, we will explain how scaper works
and show how to use scaper to synthesize soundscapes and generate corresponding
annotation files.

Create a Scaper object
----------------------
The first step is to create a ``Scaper`` object:


.. code-block:: python
    import scaper as sc
    soundcsape_duration = 10.0
    foreground_folder = 'audio/foreground/'
    background_folder = 'audio/background/'
    sc = scaper.Scaper(soundscape_duration, foreground_folder, background_folder)
    sc.ref_db = -20

We need to supply three arguments to create a ``Scaper`` object:

1. The desired duration: all soundscapes generated by this Scaper object will have this duration,
2. The path to the folder containing all foreground sounds (details below), and
3. the path to the folder containing all background sounds (details below).

The foreground folder contains all audio files scaper can use to
create foreground sound events. Within foreground, you must have a subfolder
for each sound event category (label) you want to use, for example "car_horn",
"siren", "human_voice". Within each such subfolder, scaper expects to find
audio files in wav format, where each file contains an isolated sound event of
the type indicated by the subfolder name. The filename of the WAV file is not
important as long as it ends with ``.wav``.

The background folder expects the same structure as the foreground folder,
except that it will contains audio files scaper can use as backgrounds. These
files are expected to be longer (since they should span the duration of the
soundscape we will generate) and should not contain any sound events that can
be confused with foreground events.

Here is an example of a valid folder structure for both the foreground and
backgruond folders::

    - foreground
        - siren
            - siren1.wav
            - siren2.wav
            - some_siren_sound.wav
        - car_honk
            - honk.wav
            - beep.wav
        - human_voice
            - hello_world.wav
            - shouting.wav
    - background
        - park
            - central_park.wav
        - street
            - quiet_street.wav
            - loud_street.wav

Finally, we set the reference level ``sc.ref_db``, i.e. the loudnes of the
background, measured in `LUFS <https://en.wikipedia.org/wiki/LKFS>`_. Later
when we add foreground events, we'll have to specify an ``snr``
(signal-to-noise ratio) value, i.e. by how many decibels should the foreground event
be louder (or softer) with respect to the background level specified by
``sc.ref_db``.

TIP: If you need some example sound files to experiment with scaper, you can
download or clone the
`scaper source code <https://github.com/justinsalamon/scaper>`_ which includes
audio files already organized in the correct folder structure in the tests
folder (``scaper/tests/data/audio``).

Adding a background and foreground sound events
-----------------------------------------------

Adding a background
~~~~~~~~~~~~~~~~~~~
Next, we can optionally add a background track to our soundscape:

.. code-block:: python
    sc.add_background(label=('const', 'park'),
                      source_file=('choose', []),
                      source_time=('const', 0))

To add a background we have to specify:

* ``label``: the label (category) of background, which has to match the name of one
  of the subfolders in our background folder (in our example "park" or "street"),
* ``source_file``: the path to the specific audio file to be used, and
* ``source_time``: the time in the source file from which to start the background.

Note how, in the example above, we do not specify these values directly by providing
strings or floats, but rather we provide each arugment with a tuple. These tuples
are called **distribution tuples** and are used in scaper for specifying all sound
event parameters. Let's explain:

Distribution tuples
~~~~~~~~~~~~~~~~~~~
One of the powerful things about scaper is that it allows you to define a soundscape
in a probabilistic way. That is, rather than specifying ad hoc values for each
sound event, you can specify a distribution of values to sample from. Later on,
when we call ``sc.generate()``, a soundscape will be "instantiated" by sampling a value
for each distribution tuple in each sound event (foreground and background). Every time
we call ``sc.generate()``, a new value will be sampled for each distribution tuple,
resulting in a different soundscape.

The distribution tuples currently supported by scaper are:

* ``('const', value)``: a constant, given by ``value``,
* ``('choose', list)``: uniformly sample from a finite set of values given by ``list``,
* ``('uniform', min, max)``: sample from a uniform distribution between ``min`` and ``max``,
* ``('normal', mean, std)``: sample from a normal distribution with mean ``mean`` and standard deviation ``std``, and
* ``('truncnorm', mean, std, min, max)``: sample from a truncated normal distribution with mean ``mean`` and standard deviation ``std``,
  limited to values between ``min`` and ``max``.

Special cases: the ``label`` and ``source_file`` parameters in ``sc.add_background()``
(and as we'll see later ``sc.add_event()`` as well) must be specified using
either the ``const`` or ``choose`` distribution tuples. When using ``choose``, these
two parameters (and only these) can also accept a special version of the ``choose`` tuple
in the form ``('choose', [])``, i.e. with an empty list. In this case, scaper will
use the file structure in the foreground and background folders to automatically populate
the list with all valid labels (in the case of the ``label`` parameter) and all valid
filenames (in the case of the ``source_file`` parameter).

Adding a foreground sound event
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Next, we can add foreground sound events. Let's add one to start with:

.. code-block:: python
    sc.add_event(label=('const', 'siren'),
                 source_file=('choose', []),
                 source_time=('const', 0),
                 event_time=('uniform', 0, 9),
                 event_duration=('truncnorm', 3, 1, 0.5, 5),
                 snr=('normal', 10, 3),
                 pitch_shift=('uniform', -2, 2),
                 time_stretch=('uniform', 0.8, 1.2))

A foreground sound event requires several additional parameters compared to a
background event. The full set of parameters is:

* ``label``: the label (category) of foreground event, which has to match the name of one
  of the subfolders in our foreground folder (in our example "siren", "car_honk" or "human_voice"),
* ``source_file``: the path to the specific audio file to be used,
* ``source_time``: the time in the source file from which to start the event,
* ``event_time``: the start time of the event in the synthesized soundscap,
* ``event_duration``: the duration of the event in the synthesized soundscape, and
* ``snr``: the signal-to-noise ratio (in LUFS) compared to the background. In other words,
  how many dB above or below the background should this sound event be percieved.

Scaper also supports on-the-fly augmentation of sound events, that is, applying audio
transformations to the sound events in order to increase the variability of the resulting soundscape.
Currently, the supported transformations include pitch shifting and time stretching:

* ``pitch_shift``: the number of semitones (can be fractional) by which to shift the sound up or down, and
* ``time_stretch``: the factor by which to stretch the sound event. Factors <1
  will make the event shorter, and factors >1 will make it longer.

If you do not wish to apply any transformations, these latter two parameters
(and only these) also accept ``None`` instead of a distribution tuple.

Going back to the example code above, we are adding a siren sound event,
the specific audio file to use will be chosen randomly from all available siren
audio files in the ``foreground/siren`` subfolder, the event will start at time
0 of the source file, and be "pasted" into the synthesized soundscape anywhere
between times 0 and 9 chosen uniformly. The event duration will be randomly
chosen from a truncated normal distribution with a mean of 3 seconds, standard
deviation of 1 second, and min/max values of 0.5 and 5 seconds respectively.
The loudness with respect to the background will be chosen from a normal
distribution with mean 10 dB and standard deviation of 3 dB. Finally, the pitch
of the sound event will be shifted by a value between -2 and 2 semitones
chosen uniformly within that range, and will be stretched (or condensed) by a
factor chosen uniformly between 0.8 and 1.2.

Let us add two more events:

.. code-block:: python
    for _ in range(2):
        sc.add_event(label=('choose', []),
                     source_file=('choose', []),
                     source_time=('const', 0),
                     event_time=('uniform', 0, 9),
                     event_duration=('truncnorm', 3, 1, 0.5, 5),
                     snr=('normal', 10, 3),
                     pitch_shift=None,
                     time_stretch=None)

Here we use a for loop to quickly add two sound events. The specific label and
source file for each event will be determined when we call ``sc.generate()``
(coming up), and will change with each call to this function.

Synthesizing soundscapes
------------------------
Up to this point, we have created a ``Scaper`` object and added a background and
three foreground sound events, whose parameters are specified using distribution
tuples. Internally, this creates an `event specification`, i.e. a
probabilistically defined list of sound events. To synthesize a soundscape,
we call the ``generate()`` function:

.. code-block:: python
    audiofile = 'soundscape.wav'
    jamsfile = 'soundscape.jams'
    txtfile = 'soundscape.txt'
    sc.generate(audiofile, jamsfile,
                allow_repeated_label=True,
                allow_repeated_source=False,
                reverb=0.1,
                disable_sox_warnings=True,
                no_audio=False,
                txt_path=txtfile)

This will instantiate the event specification by sampling specific parameter
values for every sound event from the distribution tuples stored in the
specification. Once all parameter values have been sampled, they are used by
scaper's audio processing engine to compose the soundscape and save the
resulting audio to ``audiofile``.

But that's not where it ends! Scaper will also generate an annotation file in
`JAMS <https://github.com/marl/jams>`_ format which serves as the reference
annotation for the generated soundscape. Due to the flexibility of the JAMS
format scaper will store in the JAMS file, in addition to the actual sound
events, the probabilistic event specification (one for background events and one
for foreground events). The ``value`` field of each observation in the JAMS file
will contain a dictionary with all instantiated parameter values. This allows
us to fully reconstruct the audio of a scaper soundscape from its JAMS annotation
using the ``scaper.generate_from_jams()`` function (not discussed in this tutorial).

Finally, we can also provide ``generate()`` a path to a text file
with the ``txt_path`` parameter. If provided, scaper will also save a simplified
annotation of the soundscape in a space-separated text file with three columns
for the start time, end time, and label of every foreground sound event (note that
the background is not stored in the simplified annotation!).

That's it! For a more detailed example of automatically synthesizing 1000
soundscapes using a single ``Scaper`` object, please see the examples.
